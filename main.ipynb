{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-07T11:54:54.998646Z",
     "start_time": "2025-08-07T11:54:54.996656Z"
    }
   },
   "source": [
    "# Martin Konečnik, https://git.siwim.si/machine-learning/fix-qa-binary-classification\n",
    "# Notebook intended for prototyping binary classification models\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from swm import factory\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T11:54:55.047866Z",
     "start_time": "2025-08-07T11:54:55.046141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the configuration file.\n",
    "with open('conf.toml', 'rb') as f:\n",
    "    conf = tomllib.load(f)\n",
    "\n",
    "EVENTS_PATH = Path().home() / conf['data_dir'] / 'prepared'\n",
    "INDEX = conf['channel']"
   ],
   "id": "85edc9890cf02265",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:02:36.638289Z",
     "start_time": "2025-08-07T11:54:55.094808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a list of training data.\n",
    "signals_unaltered = []\n",
    "signals_corrected = []\n",
    "binary_labels = []\n",
    "for event in (EVENTS_PATH / 'unaltered' / '0').iterdir():\n",
    "    data = factory.read_file(event)\n",
    "    signals_unaltered.append(data.acqdata.a[INDEX].data)\n",
    "\n",
    "for event in (EVENTS_PATH / 'corrected' / '0').iterdir():\n",
    "    data = factory.read_file(event)\n",
    "    signals_corrected.append(data.acqdata.a[INDEX].data)\n",
    "\n",
    "print(f'Unaltered signals: {len(signals_unaltered)}')\n",
    "print(f'Corrected signals: {len(signals_corrected)}')\n",
    "\n",
    "signals = signals_unaltered + signals_corrected\n",
    "binary_labels = np.array([0] * len(signals_unaltered) + [1] * len(signals_corrected))\n",
    "\n",
    "max_length = max(len(signal) for signal in signals)\n",
    "\n",
    "signals = np.array([np.pad(signal, (0, max_length - len(signal))) for signal in signals])\n",
    "binary_labels = np.array(binary_labels)\n",
    "\n",
    "print(f'Original signals shape: {signals.shape}')\n",
    "print(f'Binary labels shape: {binary_labels.shape}')  # Must be 1D."
   ],
   "id": "cf9bde92ead06eec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unaltered signals: 60309\n",
      "Corrected signals: 1192\n",
      "Original signals shape: (61501, 4329)\n",
      "Binary labels shape: (61501,)\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:03:25.558611Z",
     "start_time": "2025-08-07T12:03:24.778161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(signals, binary_labels, test_size=0.2, stratify=binary_labels)  # Stratify makes sure the random split preserves ratio of classes."
   ],
   "id": "c378d115e9b5e4ee",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:03:25.700374Z",
     "start_time": "2025-08-07T12:03:25.570762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()  # float32 for features\n",
    "y_train_tensor = torch.from_numpy(y_train).long()  # int64 for labels\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).long()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "sample_X, sample_y = next(iter(train_loader))\n",
    "print(f'Final training batch - X shape: {sample_X.shape}, y shape: {sample_y.shape}')\n",
    "print(f'X dtype: {sample_X.dtype}, y dtype: {sample_y.dtype}')  # Should be float32 and int."
   ],
   "id": "5f58f53834153f41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training batch - X shape: torch.Size([32, 4329]), y shape: torch.Size([32])\n",
      "X dtype: torch.float32, y dtype: torch.int64\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:34:34.082780Z",
     "start_time": "2025-08-07T12:34:34.070256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize model, loss function and optimizer.\n",
    "from classifier import BinaryClassifier\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(binary_labels), y=binary_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights[0]  # For consistent ratio normalize first value to 1.\n",
    "\n",
    "print(f'Class ratio {class_weights[0]} : {class_weights[1]}')\n",
    "\n",
    "model = BinaryClassifier(max_length)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(weight=class_weights[1])  # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ],
   "id": "d37510a197e20bd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio 1.0 : 50.59479904174805\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:34:55.030270Z",
     "start_time": "2025-08-07T12:34:34.111090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()  # Update loss.\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.4f}')"
   ],
   "id": "a1538607f5ed684c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 35.0778\n",
      "Epoch 2, Loss: 35.0696\n",
      "Epoch 3, Loss: 35.0696\n",
      "Epoch 4, Loss: 35.0696\n",
      "Epoch 5, Loss: 35.0696\n",
      "Epoch 6, Loss: 35.0696\n",
      "Epoch 7, Loss: 35.0696\n",
      "Epoch 8, Loss: 35.0696\n",
      "Epoch 9, Loss: 35.0696\n",
      "Epoch 10, Loss: 35.0696\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:34:55.427296Z",
     "start_time": "2025-08-07T12:34:55.042137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze() == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ],
   "id": "484d953254e2591c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.07%\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:34:55.440013Z",
     "start_time": "2025-08-07T12:34:55.433261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cestel_helpers.version import get_version\n",
    "\n",
    "ver = get_version()\n",
    "\n",
    "model_path = Path(f'models/{ver}')\n",
    "model_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), model_path / 'fix-qa-binary-classification.pth')\n",
    "\n",
    "# Save dimensions\n",
    "with open(model_path / 'dimensions', 'w') as f:\n",
    "    f.write(str(max_length))"
   ],
   "id": "6c171e4fbbe8bd69",
   "outputs": [],
   "execution_count": 87
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
