{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T11:43:14.348476Z",
     "start_time": "2025-05-07T11:43:08.605603Z"
    }
   },
   "source": [
    "# Martin KoneÄnik, http://git.siwim.si/machine-learning/fix-qa-binary-classification\n",
    "# Notebook intended for prototyping binary classification script\n",
    "import argparse\n",
    "import struct\n",
    "import sys\n",
    "import time\n",
    "import tomllib\n",
    "from collections import Counter\n",
    "from logging import DEBUG, INFO, WARNING, getLogger\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from cestel_helpers.console import configure_all\n",
    "from cestel_helpers.log import init_logger\n",
    "from cestel_helpers.version import get_version\n",
    "from lxml import etree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from swm import factory\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 13:43:11.264513: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-07 13:43:11.401223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746618191.474989   28230 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746618191.495156   28230 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746618191.633065   28230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746618191.633083   28230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746618191.633084   28230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746618191.633085   28230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 13:43:11.636942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:55:09.639944Z",
     "start_time": "2025-05-07T12:55:09.637666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the configuration file.\n",
    "with open('conf.toml', 'rb') as f:\n",
    "    conf = tomllib.load(f)\n",
    "\n",
    "UNALTERED_PATH = Path(conf['unaltered'])\n",
    "CORRECTED_PATH = Path(conf['corrected'])\n",
    "INDEX = conf['channel']"
   ],
   "id": "85edc9890cf02265",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:55:13.895240Z",
     "start_time": "2025-05-07T12:55:13.700409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get dicts of original and altered events with their size.\n",
    "is_changed: Dict[str, bool] = {}\n",
    "for unaltered_file in UNALTERED_PATH.glob('*.event'):\n",
    "    corrected_file = (CORRECTED_PATH / unaltered_file.name).exists()\n",
    "    if corrected_file.exists():\n",
    "        if unaltered_file.read_bytes() == corrected_file.read_bytes():\n",
    "            is_changed[unaltered_file.stem] = False\n",
    "        else:\n",
    "            is_changed[unaltered_file.stem] = True\n",
    "    else:\n",
    "        print(f'{unaltered_file.name} missing!')\n",
    "\n",
    "print(f'Unaltered: {Counter(is_changed.values())[True]}')\n",
    "print(f'Corrected: {Counter(is_changed.values())[False]}')"
   ],
   "id": "db67081f2309646c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unaltered: 0\n",
      "Corrected: 28822\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:26:15.458823Z",
     "start_time": "2025-05-06T13:22:15.513679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a list of training data.\n",
    "signals = []\n",
    "binary_labels = []\n",
    "for ets, status in is_changed.items():\n",
    "    path = UNALTERED_PATH / f'{ets}.event'\n",
    "    try:\n",
    "        data = factory.read_file(path)\n",
    "        signals.append(data.acqdata.a[16].data)\n",
    "        binary_labels.append(0 if status else 1)\n",
    "    except struct.error:\n",
    "        pass\n",
    "\n",
    "max_length = max(len(signal) for signal in signals)\n",
    "\n",
    "signals = np.array([np.pad(signal, (0, max_length - len(signal)), 'constant') for signal in signals])\n",
    "binary_labels = np.array(binary_labels)\n",
    "\n",
    "print(f'Original signals shape: {signals.shape}')\n",
    "print(f'Binary labels shape: {binary_labels.shape}')"
   ],
   "id": "cf9bde92ead06eec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original signals shape: (37882, 4959)\n",
      "Binary labels shape: (37882,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:26:15.655274Z",
     "start_time": "2025-05-06T13:26:15.525946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(signals, binary_labels, test_size=0.2, stratify=binary_labels)  # Stratify makes sure the random split preserves ratio of classes."
   ],
   "id": "c378d115e9b5e4ee",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:26:17.228292Z",
     "start_time": "2025-05-06T13:26:15.660071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to TF Dataset for better performance.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "# Prepare for training.\n",
    "batch = 32\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=len(X_train)).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Sanity check.\n",
    "sample_X, sample_y = next(iter(train_dataset))\n",
    "print(f'Final training batch - X shape: {sample_X.shape}, y shape: {sample_y.shape}')\n",
    "print(f'X dtype: {sample_X.dtype}, y dtype: {sample_y.dtype}')  # Should be float32 and int."
   ],
   "id": "14a8053f9ea0cf73",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746537976.250255    4196 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22348 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training batch - X shape: (32, 4959), y shape: (32,)\n",
      "X dtype: <dtype: 'float32'>, y dtype: <dtype: 'int64'>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:26:41.981986Z",
     "start_time": "2025-05-06T13:26:41.772436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()  # float32 for features\n",
    "y_train_tensor = torch.from_numpy(y_train).long()  # int64 for labels\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).long()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "sample_X, sample_y = next(iter(train_loader))\n",
    "print(f'Final training batch - X shape: {sample_X.shape}, y shape: {sample_y.shape}')\n",
    "print(f'X dtype: {sample_X.dtype}, y dtype: {sample_y.dtype}')  # Should be float32 and int."
   ],
   "id": "5f58f53834153f41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training batch - X shape: torch.Size([32, 4959]), y shape: torch.Size([32])\n",
      "X dtype: torch.float32, y dtype: torch.int64\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cbdecd8d1ec5fe45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
